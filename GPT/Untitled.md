## GPT

目标函数难找，可能某个好，但是放到别的任务上就不好

半监督，但其实现在叫自监督

## GPT-2

变大之后优势不明显

zero-shot，只训练一个模型，在所有的地方用

大部分模型泛化不行

有人提出多任务

## GPT-3

文章特别大，效果很好

作者很多但是都说了干什么

能够生成文章

技术报告

Mate-learning 很大的模型，泛化性不错

in-context learning 训练完之后，模型参数就不变了

他做few-shot其实就是在prompt里面加example

可解释性很差

