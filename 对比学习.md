# 1.百花齐放

## InstDisc

Instance Discrimination

每张图片看作一个类别

把图片放到一个特征空间里，正样本尽量集中，负样本尽量远

memory back

启发式工作

## InvaSpread

SimCLR前身

end-to-end

负样本不够多

## CPC

Contrastive Predictive Coding

预测类型的

多模态

## CMC

视角不变性

不同的传感器可以生成不同的图片，但是他们都是同一个图片，也就是说他们应该互为正样本

证明多视角的可靠性

limitation：需要配多个encoder

# 2. CV双雄

## MoCo

基本就两个东西，一个queue，一个momentum encoder，这两个点使得它可以创造一个大的字典

在实验上跟InstDisc一脉相承

写的很好

## SimCLR

很简单

一个图片做数据增强得到两张图片，这两个图片就是整样本，其他就是负样本。

最后有一个MLP做project。

跟InvaSpread一脉相承。

1. 更多的数据增强
2. 详细的消融实验
3. 非线性变换，最后一层MLP，根没加提了将近十个点

## MoCo v2

就把SimCLR的trick放到MoCo上了

## SimCLR v2

1. 更大的模型
2. 两层MLP
3. 动量编码器

非常适合半监督

## SwAV

不同视角

用其中一个预测另一个

对比学习+聚类，都是无监督

只跟聚类中心做对比

性能很好

增加了正样本的数量，但是通过一些方法使得计算成本没有增加

## CPC v2

融合很多技巧，更大的模型，更大的图像快，等等

## InfoMin

分析性的文章

# 3. 不用负样本

## BYOL

自己跟自己学

为什么不坍塌

有人说有隐藏的负样本，BN（Batch Norm）给了一个平均样本

但后面原作者有说不是这样

## SimSiam

1. 不需要负样本

2. 不需要大的batch size

3. 不用动量编码器

#  4. Transformer

## MoCo v3

大batch size反而效果差

##  DINO

 



